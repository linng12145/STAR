import os
import pandas as pd

import numpy as np
from collections import Counter
import math
import pickle

from datetime import datetime
from geopy.distance import geodesic

# ç›¸ä¼¼åˆ¤å®šä¸­çš„åˆ†ç»„mmsiæ•°é‡
mmsi_count_has_sim = 0
mmsi_count = 0

# é€šè¿‡ç»çº¬åº¦è®¡ç®—å‡ºè¿ç»­ä¸¤ç‚¹é—´çš„å®é™…è·ç¦»ğ·ğ‘–ğ‘ 
# å…¶ä¸­ğ‘…ä»£è¡¨åœ°çƒåŠå¾„ï¼Œ(ğ‘¥1 ,ğ‘¦1 )å’Œ(ğ‘¥2 ,ğ‘¦2 )åˆ†åˆ«ä»£è¡¨ä¸¤ä¸ªç‚¹ä¹‹é—´çš„ç»çº¬åº¦åæ ‡
# ğ·ğ‘–ğ‘  = ğ‘… Ã— 2000 Ã— arcsinâˆšğ·ï¼Œå…¶ä¸­Dçš„å…¬å¼ä¸º
# ğ· = {sin[0.5 Ã— (ğ‘¥2 âˆ’ ğ‘¥1)]}^2 + cosğ‘¥1 Ã— cosğ‘¥2 Ã— {sin[0.5 Ã— (ğ‘¦2 âˆ’ ğ‘¦1)]}^2
# å•ä½ï¼šç±³
def calculate_distance(data):
    # print(data)
    x1 = np.radians(data['LAT'].shift(1))
    y1 = np.radians(data['LON'].shift(1))
    x2 = np.radians(data['LAT'])
    y2 = np.radians(data['LON'])
    earth_r = 6371.393
    d = (np.sin(((x2 - x1) / 2))) ** 2 + np.cos(x1) * np.cos(x2) * ((np.sin(((y2 - y1) / 2))) ** 2)
    distance = 2000 * earth_r * np.arcsin(np.sqrt(d))

    # ä¸¤ä¸ªç‚¹ä¹‹é—´çš„ç†è®ºè·ç¦»
    time = pd.to_datetime(data['BaseDateTime'], format='%Y-%m-%dT%H:%M:%S').diff().dt.total_seconds()
    max_distance = time * 51.2 * 1852 / 3600

    data['Distance'] = distance.fillna(0)
    data['MaxDistance'] = max_distance.fillna(0)

    return data


# æ•°å€¼å‹æ•°æ®çš„ç›¸ä¼¼åˆ¤æ–­
def similar_number(num1, num2):
    if pd.isna(num1) and pd.isna(num2):
        return 1
    if pd.isna(num1) or pd.isna(num2):
        return 0
    if max(num1, num2) == 0:
        if num1 == num2:
            return 1
        else:
            return 0
    sim = 1 - abs((num1 - num2) / max(num1, num2))
    return sim


# å­—ç¬¦å‹æ•°æ®çš„ç›¸ä¼¼åˆ¤æ–­
# ä½™å¼¦ç›¸ä¼¼åº¦ç®—æ³•
def similar_string(str1, str2):
    if pd.isna(str1) and pd.isna(str2):
        return 1
    if pd.isna(str1) or pd.isna(str2):
        return 0
    vector1 = Counter(list(str1))
    vector2 = Counter(list(str2))

    shared = set(vector1.keys()) & set(vector2.keys())
    numerator = sum([vector1[x] * vector2[x] for x in shared])

    sum1 = sum([vector1[x] ** 2 for x in vector1.keys()])
    sum2 = sum([vector2[x] ** 2 for x in vector2.keys()])
    denominator = math.sqrt(sum1 * sum2)

    if not denominator:
        return 0.0
    else:
        return float(numerator) / denominator


# å¸ƒå°”å‹æ•°æ®çš„ç›¸ä¼¼åˆ¤æ–­
# å¦‚èˆ¹èˆ¶çš„ AIS è®¾å¤‡ç§ç±»è¡¨ç¤ºä¸º A ç±»å’Œ B ç±»ï¼Œä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼Œå°† A ç±»è®°ä¸º 0ï¼ŒB ç±»è®°ä¸º 1
def similar_bool(bool1, bool2):
    if pd.isna(bool1) and pd.isna(bool2):
        return 1
    if pd.isna(bool1) or pd.isna(bool2):
        return 0
    return bool1 == bool2


# æ•°æ®çš„ç›¸ä¼¼åˆ¤æ–­
def similar(wei, row1, row2):
    # sim_mmsi = similar_number(row1['MMSI'], row2['MMSI'])
    sim_time = similar_string(row1['BaseDateTime'], row2['BaseDateTime'])
    sim_lat = similar_number(row1['LAT'], row2['LAT'])
    sim_lon = similar_number(row1['LON'], row2['LON'])
    sim_sog = similar_number(row1['SOG'], row2['SOG'])
    sim_cog = similar_number(row1['COG'], row2['COG'])
    sim_heading = similar_number(row1['Heading'], row2['Heading'])
    sim_vessel_name = similar_string(row1['VesselName'], row2['VesselName'])
    sim_imo = similar_string(row1['IMO'], row2['IMO'])
    sim_call_sign = similar_string(row1['CallSign'], row2['CallSign'])
    sim_vessel_type = similar_number(row1['VesselType'], row2['VesselType'])
    sim_status = similar_number(row1['Status'], row2['Status'])
    sim_length = similar_number(row1['Length'], row2['Length'])
    sim_width = similar_number(row1['Width'], row2['Width'])
    sim_draft = similar_number(row1['Draft'], row2['Draft'])
    sim_cargo = similar_number(row1['Cargo'], row2['Cargo'])
    sim_transceiver_class = similar_bool(row1['TransceiverClass'], row2['TransceiverClass'])
    sim = np.array(
        [
            sim_time,
            sim_lat, sim_lon, sim_sog, sim_cog, sim_heading, sim_vessel_name, sim_imo, sim_call_sign,
         sim_vessel_type, sim_status, sim_length, sim_width, sim_draft, sim_cargo, sim_transceiver_class])
    # å¸¦æƒé‡çš„ç›¸ä¼¼åº¦
    wei_sim = np.sum(sim * wei)
    is_sim = wei_sim > 0.95
    # print(wei_sim)
    # print(is_sim)
    return is_sim
    # print(
    #     f"sim_MMSI\n{sim_mmsi}\n"
    #     f"sim_time\n{sim_time}\n"
    #     f"sim_lat\n{sim_lat}\n"
    #     f"sim_lon\n{sim_lon}\n"
    #     f"sim_sog\n{sim_sog}\n"
    #     f"sim_cog\n{sim_cog}\n"
    #     f"sim_heading\n{sim_heading}\n"
    #     f"sim_vessel_name\n{sim_vessel_name}\n"
    #     f"sim_imo\n{sim_imo}\n"
    #     f"sim_call_sign\n{sim_call_sign}\n"
    #     f"sim_vessel_type\n{sim_vessel_type}\n"
    #     f"sim_status\n{sim_status}\n"
    #     f"sim_length\n{sim_length}\n"
    #     f"sim_width\n{sim_width}\n"
    #     f"sim_draft\n{sim_draft}\n"
    #     f"sim_cargo\n{sim_cargo}\n"
    #     f"sim_transceiver_class\n{sim_transceiver_class}\n"
    # )


# æ”¹è¿›çš„åŠ¨æ€æ»‘åŠ¨çª—å£ç­–ç•¥
def dynamic_window(data, wei, initial_window_size, threshold):
    global mmsi_count_has_sim, mmsi_count
    mmsi_count_has_sim += 1
    print(f"{mmsi_count_has_sim}/{mmsi_count}")
    window_size = initial_window_size
    counter = 0
    repetition_number = []
    for begin in range(0, len(data)):
        # print(f"repetition\n{repetition_number}\n")
        # print(f"begin\n{begin}\n")
        if begin in repetition_number:
            continue
        compared = 0
        window_begin = begin
        now = window_begin + 1
        while compared < window_size:
            if now >= len(data):
                break
            # çª—å£å°ºå¯¸æ‰©å¤§
            # å°†çª—å£å†…æ•°æ®åˆ†åˆ«ä¸çª—å£ç¬¬ä¸€ä¸ªæ•°æ®è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—ï¼Œ
            # å½“æ£€æµ‹åˆ°æ•°æ®ğ‘Š(ğ‘˜)ä¸æ•°æ®ğ‘Š(ğ‘–)ç›¸ä¼¼æ—¶ï¼Œå…¶ä¸­ğ‘– < ğ‘˜ â‰¤ ğ‘—ï¼Œå¯¹çª—å£è¿›è¡Œæ‰©å¤§
            if similar(wei, data.iloc[window_begin], data.iloc[now]):
                window_change = window_size - 1
                window_size = now - window_begin + 1 + window_change
                repetition_number.append(now)
                data.loc[data.index[now], 'ISSIMILAR'] = 1
                # print(data)

                # çª—å£å°ºå¯¸ç¼©å°
                # å½“æ£€æµ‹åˆ°ä¸€ä¸ªä¸é‡å¤æ•°æ®ï¼Œåˆ™ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿçš„å€¼åŠ ä¸€ï¼Œå½“ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿè¶…è¿‡é˜ˆå€¼ï¼Œæå‰ç»“æŸçª—å£ï¼Œå¹¶ç¼©å°çª—å£
            else:
                counter += 1
                if counter > threshold:
                    window_change = window_size - counter - 1
                    window_size = now - window_begin + 1 - window_change
                    counter = 0
                    break
            compared += 1
            now += 1
    return data

def save_file(df, output_path, new_filename):
    # ä¿å­˜å¤„ç†åçš„æ•°æ®é›†
    output_path = os.path.join(output_path, new_filename)
    df.to_csv(output_path, index=False)

# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶
# for filename in os.listdir(input_folder):
#     if filename.endswith('.csv'):

def data_clean(df):

    global mmsi_count_has_sim, mmsi_count
    # ç›¸ä¼¼åˆ¤å®šä¸­çš„åˆ†ç»„mmsiæ•°é‡
    mmsi_count_has_sim = 0

    # Load the dataset

    # print(df.head())

    # 1. å°† AIS æ•°æ®æŒ‰ MMSI å’Œæ—¶é—´å‡å¹‚æ’åº
    df.sort_values(by=['MMSI', 'BaseDateTime'], inplace=True)
    df.reset_index(drop=True, inplace=True)
    print("1 å°† AIS æ•°æ®æŒ‰ MMSI å’Œæ—¶é—´å‡å¹‚æ’åº end")
    print("len(df):{}\n".format(len(df)))
    # print(df)

    # 2. åˆ é™¤ MMSI ä¸ä¸º 9 ä½çš„æ•°æ®
    df = df[df['MMSI'].apply(lambda x: len(str(x)) == 9)]
    print("2 åˆ é™¤ MMSI ä¸ä¸º 9 ä½çš„æ•°æ® end")
    print("len(df):{}\n".format(len(df)))

    # 3. åˆ é™¤MMSIç›¸åŒã€IMOä¸åŒçš„æƒ…å†µï¼Œä¸€èˆ¬ä¸ºå¥—ç‰Œèˆ¹
    # print(df)
    df = df.groupby('MMSI').filter(lambda x: x['IMO'].nunique() <= 1)
    # print(df)
    print("3 åˆ é™¤MMSIç›¸åŒã€IMOä¸åŒçš„æƒ…å†µï¼Œä¸€èˆ¬ä¸ºå¥—ç‰Œèˆ¹ end")
    print("len(df):{}\n".format(len(df)))

    # 4. åˆ é™¤ä¸€å¤©å†…çš„AISæ•°æ®ä¸è¶³50æ¡çš„è½¨è¿¹
    # print(df)
    df = df.groupby('MMSI').filter(lambda x: x['MMSI'].count() > 50)
    # print(df)
    print("4 åˆ é™¤ä¸€å¤©å†…çš„AISæ•°æ®ä¸è¶³1050æ¡çš„è½¨è¿¹ end")
    print("len(df):{}\n".format(len(df)))

    # 5. åˆ é™¤çŠ¶æ€ä¸º1çš„è½¨è¿¹ç‚¹
    df = df[df['Status'] != 1]
    print("5 åˆ é™¤çŠ¶æ€ä¸º1çš„è½¨è¿¹ç‚¹ end")
    print("len(df):{}\n".format(len(df)))

    # 6. åˆ é™¤èˆ¹é•¿å°äº 3 å’Œèˆ¹å®½å°äº 2 çš„èˆ¹èˆ¶æ•°æ®
    df = df[(df['Length'] >= 3) & (df['Width'] >= 2)]
    print("6 åˆ é™¤èˆ¹é•¿å°äº 3 å’Œèˆ¹å®½å°äº 2 çš„èˆ¹èˆ¶æ•°æ® end")
    print("len(df):{}\n".format(len(df)))

    # 7. åˆ é™¤è¶…å‡ºæœ‰æ•ˆèŒƒå›´çš„ç»åº¦ã€ç»´åº¦ã€å¯¹åœ°èˆªé€Ÿã€å¯¹åœ°èˆªå‘æ•°æ®
    df = df[(df['LON'] >= -180.0) & (df['LON'] <= 180.0)]
    df = df[(df['LAT'] >= -90.0) & (df['LAT'] <= 90.0)]
    df = df[(df['SOG'] > 0) & (df['SOG'] <= 24)]
    df = df[(df['COG'] >= 0) & (df['COG'] <= 409.6)]
    print("7 åˆ é™¤è¶…å‡ºæœ‰æ•ˆèŒƒå›´çš„ç»åº¦ã€ç»´åº¦ã€å¯¹åœ°èˆªé€Ÿã€å¯¹åœ°èˆªå‘æ•°æ® end")
    print("len(df):{}\n".format(len(df)))

    # 8. åˆ é™¤ç»çº¬åº¦æ˜æ˜¾æ¼‚ç§»çš„æ•°æ®
    df = df.groupby('MMSI').apply(calculate_distance, include_groups=False).reset_index(level=0)
    # print(df)

    # æ’é™¤ä¸å‰åä¸¤ä¸ªç‚¹ä¹‹é—´å®é™…è·ç¦»å‡å¤§äºç†è®ºè·ç¦»çš„ç‚¹
    distance_shift = df['Distance'].shift(-1).fillna(0)
    max_distance_shift = df['MaxDistance'].shift(-1).fillna(0)
    df = df[(df['Distance'] <= df['MaxDistance']) | (distance_shift <= max_distance_shift)]

    # df.drop(columns=['Distance', 'MaxDistance'], inplace=True)
    # print(df)
    print("8 åˆ é™¤ç»çº¬åº¦æ˜æ˜¾æ¼‚ç§»çš„æ•°æ® end")
    print("before df len:{}\n".format(len(df)))

    # # 9. åˆ é™¤ç›¸ä¼¼é‡å¤çš„æ•°æ®
    # # æ±‚å»æ‰mmsiçš„å„åˆ—æƒé‡
    # # df_without_mmsi = df.drop(columns=['MMSI', 'BaseDateTime', 'Distance', 'MaxDistance'], axis=1)
    # df_without_mmsi = df.drop(columns=['MMSI', 'Distance', 'MaxDistance'], axis=1)
    #
    # # print(df_without_mmsi)
    # num_unique = df_without_mmsi.nunique()
    # total_unique = num_unique.sum()
    # weight = num_unique / total_unique
    # print(f"ç§ç±»æ•°é‡:\n {num_unique}\nç§ç±»æ€»æ•°:\n{total_unique}\næƒé‡:\n{weight}")
    # mmsi_count = df['MMSI'].nunique()
    # print('mmsi_count: {}'.format(df['MMSI'].nunique()))
    # # print(df)
    # # åˆ é™¤ç›¸ä¼¼æ•°æ®
    # df['ISSIMILAR'] = 0
    # df = df.groupby('MMSI').apply(dynamic_window, wei=weight, initial_window_size=5, threshold=5,
    #                               include_groups=False).reset_index(level=0)
    # # print(df.head())
    #
    # df = df[df['ISSIMILAR'] == 0]
    # df = df.drop('ISSIMILAR', axis=1)
    # # print(df)
    # print("9 åˆ é™¤é‡å¤çš„æ•°æ® end")
    # print("after df len:{}\n".format(len(df)))

    df.drop(columns=['Distance', 'MaxDistance'], inplace=True)
    df.reset_index(drop=True, inplace=True)
    # print(df)

    return df


def process_file(input_folder, lon_min, lon_max, lat_min, lat_max):
    df = pd.DataFrame()
    file_count = 0

    for filename in os.listdir(input_folder):
        # if filename != "AIS_2023_12_30.csv":
        #     continue
        if filename.endswith('.csv'):
            file_path = os.path.join(input_folder, filename)

            print("{}: {} begin".format(file_count, filename))
            # è¯»å–csvæ–‡ä»¶çš„å†…å®¹
            temp_df = pd.read_csv(file_path)

            temp_df = temp_df[((temp_df['LON'] >= lon_min) & (temp_df['LON'] < lon_max) &
                            (temp_df['LAT'] >= lat_min) & (temp_df['LAT'] < lat_max))]

            temp_df = data_clean(temp_df)

            # åªä¿ç•™éƒ¨åˆ†
            temp_df = temp_df[['MMSI', 'BaseDateTime', 'LAT', 'LON', 'COG', 'SOG']]

            # save_file(temp_df, '../data/AIS/AIS_2023_101112', filename)

            df = pd.concat([df, temp_df])
            # print("df len:{}\n".format(len(df)))

            print(f"{filename} end")


            # for lon_min, lon_max, lat_min, lat_max in zip(LON_min, LON_max, LAT_min, LAT_max):
            #
            #     temp_df1 = temp_df[((temp_df['LON'] >= lon_min) & (temp_df['LON'] < lon_max) &
            #                        (temp_df['LAT'] >= lat_min) & (temp_df['LAT'] < lat_max))]
            #     df = pd.concat([df, temp_df1])
            #     print("len(temp_df1):{} len(df):{}".format(len(temp_df1), len(df)))


            # å°†è¯»å–çš„å†…å®¹æ·»åŠ åˆ°dfä¸­
            # df = pd.concat([df, temp_df])

            print("{}: {} end".format(file_count, filename))

            file_count = file_count + 1

    return df


def save_file(df, output_path, new_filename):
    # ä¿å­˜å¤„ç†åçš„æ•°æ®é›†
    output_path = os.path.join(output_path, new_filename)
    df.to_csv(output_path, index=False)


def gather():

    input_folders = ['../data/AIS_2023_09', '../data/AIS_2023_10', '../data/AIS_2023_11', '../data/AIS_2023_12']

    df = pd.DataFrame()
    # LON_min = [-95.5, -94.8,  -91.18, -88.7, -85.6, -83.5, -82.6, -81.4]
    # LON_max = [-83.5, -91.18, -89.5,  -85.6, -83.5, -82.6, -81.4, -79.0]
    # LAT_min = [ 23.5,  28.8,   28.8,   28.8,  28.8,  23.3,  23.3,  23.3]
    # LAT_max = [ 28.8,  29.2,   29.0,   30.0,  29.5,  27.0,  25.6,  24.8]

    # lon_min = -97.6
    # lon_max = -79
    # lat_min = 24.5
    # lat_max = 30.5

    lon_min = -95.6
    lon_max = -80.0
    lat_min = 28.5
    lat_max = 30.5

    file_count = 0

    for folder in input_folders:
        temp_df = process_file(folder, lon_min, lon_max, lat_min, lat_max)
        df = pd.concat([df, temp_df])
        file_count += 1



    save_file(df, '../data/AIS/AIS_2023_4month', 'AIS_2023_4month.csv')
    print("finish")


gather()


